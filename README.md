# Movies-ETL

## Project Overview
Create an automated pipeline that takes in new data, performs the appropriate transformations, and loads the data into existing tables. You’ll need to refactor the code from this module to create one function that takes in the three files—Wikipedia data, Kaggle metadata, and the MovieLens rating data—and performs the ETL process by adding the data to a PostgreSQL database.

## Resources
- Data Source: movies_metadata.csv, ratings.csv, wikipedia_movies.json
- Software: Jupyter Notebook, PostgreSQL

## Challenge Overview
Consists of four technical analysis deliverables:

Deliverable 1: Write an ETL Function to Read Three Data Files
Deliverable 2: Extract and Transform the Wikipedia Data
Deliverable 3: Extract and Transform the Kaggle data
Deliverable 4: Create the Movie Database

## Results

### Deliverable 1: Write an ETL function to read three data files
ETL_function_test.ipynb

### Deliverable 2: Extract and Transform the Wikipedia Data
ETL_clean_wiki_movies.ipynb

### Deliverable 3: Extract and Transform the Kaggle Data
ETL_clean_kaggle_data.ipynb

### Deliverable 4: Create the Movie Database
ETL_create_database.ipynb

## Summary
